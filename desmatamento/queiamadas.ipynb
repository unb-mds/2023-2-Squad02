{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amandacampos/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import basedosdados as bd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "BaseDosDadosAccessDeniedException",
     "evalue": "\nAre you sure you are using the right `billing_project_id`?\nYou must use the Project ID available in your Google Cloud console home page at https://console.cloud.google.com/home/dashboard\nIf you still don't have a Google Cloud Project, you have to create one.\nYou can set one up by following these steps: \n1. Go to this link https://console.cloud.google.com/projectselector2/home/dashboard\n2. Agree with Terms of Service if asked\n3. Click in Create Project\n4. Put a cool name in your project\n5. Hit create\n6. Rerun this command with the flag `reauth=True`. \n   Like `read_table('br_ibge_pib', 'municipios', billing_project_id=<YOUR_PROJECT_ID>, reauth=True)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas_gbq/gbq.py:469\u001b[0m, in \u001b[0;36mGbqConnector.run_query\u001b[0;34m(self, query, max_results, progress_bar_type, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mRequesting query... \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 469\u001b[0m query_reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mquery(\n\u001b[1;32m    470\u001b[0m     query,\n\u001b[1;32m    471\u001b[0m     job_config\u001b[39m=\u001b[39;49mbigquery\u001b[39m.\u001b[39;49mQueryJobConfig\u001b[39m.\u001b[39;49mfrom_api_repr(job_config),\n\u001b[1;32m    472\u001b[0m     location\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlocation,\n\u001b[1;32m    473\u001b[0m     project\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproject_id,\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    475\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mQuery running...\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/cloud/bigquery/client.py:3345\u001b[0m, in \u001b[0;36mClient.query\u001b[0;34m(self, query, job_config, job_id, job_id_prefix, location, project, retry, timeout, job_retry)\u001b[0m\n\u001b[1;32m   3343\u001b[0m         \u001b[39mreturn\u001b[39;00m query_job\n\u001b[0;32m-> 3345\u001b[0m future \u001b[39m=\u001b[39m do_query()\n\u001b[1;32m   3346\u001b[0m \u001b[39m# The future might be in a failed state now, but if it's\u001b[39;00m\n\u001b[1;32m   3347\u001b[0m \u001b[39m# unrecoverable, we'll find out when we ask for it's result, at which\u001b[39;00m\n\u001b[1;32m   3348\u001b[0m \u001b[39m# point, we may retry.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/cloud/bigquery/client.py:3322\u001b[0m, in \u001b[0;36mClient.query.<locals>.do_query\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3321\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3322\u001b[0m     query_job\u001b[39m.\u001b[39;49m_begin(retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   3323\u001b[0m \u001b[39mexcept\u001b[39;00m core_exceptions\u001b[39m.\u001b[39mConflict \u001b[39mas\u001b[39;00m create_exc:\n\u001b[1;32m   3324\u001b[0m     \u001b[39m# The thought is if someone is providing their own job IDs and they get\u001b[39;00m\n\u001b[1;32m   3325\u001b[0m     \u001b[39m# their job ID generation wrong, this could end up returning results for\u001b[39;00m\n\u001b[1;32m   3326\u001b[0m     \u001b[39m# the wrong query. We thus only try to recover if job ID was not given.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/cloud/bigquery/job/query.py:1252\u001b[0m, in \u001b[0;36mQueryJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m   1251\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1252\u001b[0m     \u001b[39msuper\u001b[39;49m(QueryJob, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_begin(client\u001b[39m=\u001b[39;49mclient, retry\u001b[39m=\u001b[39;49mretry, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1253\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mGoogleAPICallError \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/cloud/bigquery/job/base.py:509\u001b[0m, in \u001b[0;36m_AsyncJob._begin\u001b[0;34m(self, client, retry, timeout)\u001b[0m\n\u001b[1;32m    508\u001b[0m span_attributes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m\"\u001b[39m: path}\n\u001b[0;32m--> 509\u001b[0m api_response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49m_call_api(\n\u001b[1;32m    510\u001b[0m     retry,\n\u001b[1;32m    511\u001b[0m     span_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mBigQuery.job.begin\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    512\u001b[0m     span_attributes\u001b[39m=\u001b[39;49mspan_attributes,\n\u001b[1;32m    513\u001b[0m     job_ref\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    514\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    515\u001b[0m     path\u001b[39m=\u001b[39;49mpath,\n\u001b[1;32m    516\u001b[0m     data\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_api_repr(),\n\u001b[1;32m    517\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    518\u001b[0m )\n\u001b[1;32m    519\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_properties(api_response)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/cloud/bigquery/client.py:760\u001b[0m, in \u001b[0;36mClient._call_api\u001b[0;34m(self, retry, span_name, span_attributes, job_ref, headers, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[39mwith\u001b[39;00m create_span(\n\u001b[1;32m    758\u001b[0m         name\u001b[39m=\u001b[39mspan_name, attributes\u001b[39m=\u001b[39mspan_attributes, client\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, job_ref\u001b[39m=\u001b[39mjob_ref\n\u001b[1;32m    759\u001b[0m     ):\n\u001b[0;32m--> 760\u001b[0m         \u001b[39mreturn\u001b[39;00m call()\n\u001b[1;32m    762\u001b[0m \u001b[39mreturn\u001b[39;00m call()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/retry.py:349\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m sleep_generator \u001b[39m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    347\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maximum, multiplier\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multiplier\n\u001b[1;32m    348\u001b[0m )\n\u001b[0;32m--> 349\u001b[0m \u001b[39mreturn\u001b[39;00m retry_target(\n\u001b[1;32m    350\u001b[0m     target,\n\u001b[1;32m    351\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predicate,\n\u001b[1;32m    352\u001b[0m     sleep_generator,\n\u001b[1;32m    353\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_timeout,\n\u001b[1;32m    354\u001b[0m     on_error\u001b[39m=\u001b[39;49mon_error,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/api_core/retry.py:191\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m     \u001b[39mreturn\u001b[39;00m target()\n\u001b[1;32m    193\u001b[0m \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[39m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/cloud/_http/__init__.py:494\u001b[0m, in \u001b[0;36mJSONConnection.api_request\u001b[0;34m(self, method, path, query_params, data, content_type, headers, api_base_url, api_version, expect_json, _target_object, timeout, extra_api_info)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 494\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mfrom_http_response(response)\n\u001b[1;32m    496\u001b[0m \u001b[39mif\u001b[39;00m expect_json \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mcontent:\n",
      "\u001b[0;31mForbidden\u001b[0m: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/serene-mender-291402/jobs?prettyPrint=false: Access Denied: Project serene-mender-291402: User does not have bigquery.jobs.create permission in project serene-mender-291402.\n\n(job ID: efa6a7a8-17b5-46a3-9993-4a8f700f951a)\n\n                -----Query Job SQL Follows-----                \n\n    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:        SELECT * \n   3:        FROM `basedosdados.br_inpe_prodes.municipio_bioma`\n    |    .    |    .    |    .    |    .    |    .    |",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mGenericGBQException\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/basedosdados/download/download.py:82\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(query, billing_project_id, from_file, reauth, use_bqstorage_api)\u001b[0m\n\u001b[1;32m     77\u001b[0m     bigquery_storage_v1\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mBigQueryReadClient\u001b[39m.\u001b[39mread_rows \u001b[39m=\u001b[39m partialmethod(\n\u001b[1;32m     78\u001b[0m         bigquery_storage_v1\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mBigQueryReadClient\u001b[39m.\u001b[39mread_rows,\n\u001b[1;32m     79\u001b[0m         timeout\u001b[39m=\u001b[39m\u001b[39m3600\u001b[39m \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m,\n\u001b[1;32m     80\u001b[0m     )\n\u001b[0;32m---> 82\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_gbq\u001b[39m.\u001b[39;49mread_gbq(\n\u001b[1;32m     83\u001b[0m         query,\n\u001b[1;32m     84\u001b[0m         credentials\u001b[39m=\u001b[39;49mcredentials(from_file\u001b[39m=\u001b[39;49mfrom_file, reauth\u001b[39m=\u001b[39;49mreauth),\n\u001b[1;32m     85\u001b[0m         project_id\u001b[39m=\u001b[39;49mbilling_project_id,\n\u001b[1;32m     86\u001b[0m         use_bqstorage_api\u001b[39m=\u001b[39;49muse_bqstorage_api,\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m GenericGBQException \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas_gbq/gbq.py:921\u001b[0m, in \u001b[0;36mread_gbq\u001b[0;34m(query_or_table, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, verbose, private_key, progress_bar_type, dtypes)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m _is_query(query_or_table):\n\u001b[0;32m--> 921\u001b[0m     final_df \u001b[39m=\u001b[39m connector\u001b[39m.\u001b[39;49mrun_query(\n\u001b[1;32m    922\u001b[0m         query_or_table,\n\u001b[1;32m    923\u001b[0m         configuration\u001b[39m=\u001b[39;49mconfiguration,\n\u001b[1;32m    924\u001b[0m         max_results\u001b[39m=\u001b[39;49mmax_results,\n\u001b[1;32m    925\u001b[0m         progress_bar_type\u001b[39m=\u001b[39;49mprogress_bar_type,\n\u001b[1;32m    926\u001b[0m         dtypes\u001b[39m=\u001b[39;49mdtypes,\n\u001b[1;32m    927\u001b[0m     )\n\u001b[1;32m    928\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas_gbq/gbq.py:485\u001b[0m, in \u001b[0;36mGbqConnector.run_query\u001b[0;34m(self, query, max_results, progress_bar_type, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhttp_error \u001b[39mas\u001b[39;00m ex:\n\u001b[0;32m--> 485\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess_http_error(ex)\n\u001b[1;32m    487\u001b[0m job_id \u001b[39m=\u001b[39m query_reply\u001b[39m.\u001b[39mjob_id\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas_gbq/gbq.py:386\u001b[0m, in \u001b[0;36mGbqConnector.process_http_error\u001b[0;34m(ex)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[39mraise\u001b[39;00m QueryTimeout(\u001b[39m\"\u001b[39m\u001b[39mReason: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(ex))\n\u001b[0;32m--> 386\u001b[0m \u001b[39mraise\u001b[39;00m GenericGBQException(\u001b[39m\"\u001b[39m\u001b[39mReason: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(ex))\n",
      "\u001b[0;31mGenericGBQException\u001b[0m: Reason: 403 POST https://bigquery.googleapis.com/bigquery/v2/projects/serene-mender-291402/jobs?prettyPrint=false: Access Denied: Project serene-mender-291402: User does not have bigquery.jobs.create permission in project serene-mender-291402.\n\n(job ID: efa6a7a8-17b5-46a3-9993-4a8f700f951a)\n\n                -----Query Job SQL Follows-----                \n\n    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:        SELECT * \n   3:        FROM `basedosdados.br_inpe_prodes.municipio_bioma`\n    |    .    |    .    |    .    |    .    |    .    |",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBaseDosDadosAccessDeniedException\u001b[0m         Traceback (most recent call last)",
      "\u001b[1;32m/Users/amandacampos/UnB/Curso/2023.2/MDS/2023-2-Squad02/desmatamento/queiamadas.ipynb Célula 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/amandacampos/UnB/Curso/2023.2/MDS/2023-2-Squad02/desmatamento/queiamadas.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Para carregar o dado direto no pandas\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/amandacampos/UnB/Curso/2023.2/MDS/2023-2-Squad02/desmatamento/queiamadas.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m bd\u001b[39m.\u001b[39;49mread_table(dataset_id\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mbr_inpe_prodes\u001b[39;49m\u001b[39m'\u001b[39;49m,table_id\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmunicipio_bioma\u001b[39;49m\u001b[39m'\u001b[39;49m,billing_project_id\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mserene-mender-291402\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/basedosdados/download/download.py:163\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(dataset_id, table_id, billing_project_id, query_project_id, limit, from_file, reauth, use_bqstorage_api)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[39mraise\u001b[39;00m BaseDosDadosException(\u001b[39m\"\u001b[39m\u001b[39mBoth table_id and dataset_id should be filled.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m \u001b[39mreturn\u001b[39;00m read_sql(\n\u001b[1;32m    164\u001b[0m     query,\n\u001b[1;32m    165\u001b[0m     billing_project_id\u001b[39m=\u001b[39;49mbilling_project_id,\n\u001b[1;32m    166\u001b[0m     from_file\u001b[39m=\u001b[39;49mfrom_file,\n\u001b[1;32m    167\u001b[0m     reauth\u001b[39m=\u001b[39;49mreauth,\n\u001b[1;32m    168\u001b[0m     use_bqstorage_api\u001b[39m=\u001b[39;49muse_bqstorage_api,\n\u001b[1;32m    169\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/basedosdados/download/download.py:91\u001b[0m, in \u001b[0;36mread_sql\u001b[0;34m(query, billing_project_id, from_file, reauth, use_bqstorage_api)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mexcept\u001b[39;00m GenericGBQException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mReason: 403\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n\u001b[0;32m---> 91\u001b[0m         \u001b[39mraise\u001b[39;00m BaseDosDadosAccessDeniedException \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m re\u001b[39m.\u001b[39mmatch(\u001b[39m\"\u001b[39m\u001b[39mReason: 400 POST .* [Pp]roject[ ]*I[Dd]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(e)):\n\u001b[1;32m     94\u001b[0m         \u001b[39mraise\u001b[39;00m BaseDosDadosInvalidProjectIDException \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mBaseDosDadosAccessDeniedException\u001b[0m: \nAre you sure you are using the right `billing_project_id`?\nYou must use the Project ID available in your Google Cloud console home page at https://console.cloud.google.com/home/dashboard\nIf you still don't have a Google Cloud Project, you have to create one.\nYou can set one up by following these steps: \n1. Go to this link https://console.cloud.google.com/projectselector2/home/dashboard\n2. Agree with Terms of Service if asked\n3. Click in Create Project\n4. Put a cool name in your project\n5. Hit create\n6. Rerun this command with the flag `reauth=True`. \n   Like `read_table('br_ibge_pib', 'municipios', billing_project_id=<YOUR_PROJECT_ID>, reauth=True)`"
     ]
    }
   ],
   "source": [
    "# Para carregar o dado direto no pandas\n",
    "df = bd.read_table(dataset_id='br_inpe_prodes',table_id='municipio_bioma',billing_project_id=\"serene-mender-291402\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertendo codigos dos municipios para seus respectivos nomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING *** OLE2 inconsistency: SSCS size is 0 but SSAT size is non-zero\n",
      "*** No CODEPAGE record, no encoding_override: will use 'iso-8859-1'\n"
     ]
    }
   ],
   "source": [
    "caminho_arquivo = './RELATORIO_DTB_BRASIL_MUNICIPIO.xls' \n",
    "ibge_df = pd.read_excel(caminho_arquivo)\n",
    "\n",
    "selecao = ibge_df[ibge_df['Unnamed: 1'] == 'Amazonas']\n",
    "amazonas_df = pd.DataFrame(selecao).reset_index(drop=True)\n",
    "colunas_para_manter = ['Unnamed: 11', 'Unnamed: 12']\n",
    "amazonas_df = amazonas_df[colunas_para_manter]\n",
    "municipios_amazonas = amazonas_df.set_index('Unnamed: 11')['Unnamed: 12'].to_dict()\n",
    "#print(municipios_amazonas)\n",
    "\n",
    "df_amazonas = df[df['id_municipio'].isin(municipios_amazonas.keys())]\n",
    "df_amazonas['id_municipio'] = df_amazonas['id_municipio'].map(municipios_amazonas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando dados somente do estado do Amazonas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renomeando coluna e salva dados do amazonas\n",
    "df_amazonas = df_amazonas.rename(columns={'id_municipio': 'municipio'})\n",
    "df_amazonas.to_csv('amazonas_desmatamento.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ano</th>\n",
       "      <th>municipio</th>\n",
       "      <th>bioma</th>\n",
       "      <th>area_total</th>\n",
       "      <th>desmatado</th>\n",
       "      <th>vegetacao_natural</th>\n",
       "      <th>nao_vegetacao_natural</th>\n",
       "      <th>hidrografia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12259</td>\n",
       "      <td>2006</td>\n",
       "      <td>Santo Antônio do Içá</td>\n",
       "      <td>Amazônia</td>\n",
       "      <td>12306</td>\n",
       "      <td>130.0</td>\n",
       "      <td>11650.7</td>\n",
       "      <td>89.4</td>\n",
       "      <td>435.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12260</td>\n",
       "      <td>2009</td>\n",
       "      <td>Santo Antônio do Içá</td>\n",
       "      <td>Amazônia</td>\n",
       "      <td>12306</td>\n",
       "      <td>133.4</td>\n",
       "      <td>11647.3</td>\n",
       "      <td>89.4</td>\n",
       "      <td>435.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12261</td>\n",
       "      <td>2014</td>\n",
       "      <td>Santo Antônio do Içá</td>\n",
       "      <td>Amazônia</td>\n",
       "      <td>12306</td>\n",
       "      <td>137.2</td>\n",
       "      <td>11643.5</td>\n",
       "      <td>89.4</td>\n",
       "      <td>435.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12262</td>\n",
       "      <td>2010</td>\n",
       "      <td>Santo Antônio do Içá</td>\n",
       "      <td>Amazônia</td>\n",
       "      <td>12306</td>\n",
       "      <td>134.2</td>\n",
       "      <td>11646.5</td>\n",
       "      <td>89.4</td>\n",
       "      <td>435.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12263</td>\n",
       "      <td>2012</td>\n",
       "      <td>Santo Antônio do Içá</td>\n",
       "      <td>Amazônia</td>\n",
       "      <td>12306</td>\n",
       "      <td>137.2</td>\n",
       "      <td>11643.5</td>\n",
       "      <td>89.4</td>\n",
       "      <td>435.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   ano             municipio     bioma  area_total  desmatado  \\\n",
       "0       12259  2006  Santo Antônio do Içá  Amazônia       12306      130.0   \n",
       "1       12260  2009  Santo Antônio do Içá  Amazônia       12306      133.4   \n",
       "2       12261  2014  Santo Antônio do Içá  Amazônia       12306      137.2   \n",
       "3       12262  2010  Santo Antônio do Içá  Amazônia       12306      134.2   \n",
       "4       12263  2012  Santo Antônio do Içá  Amazônia       12306      137.2   \n",
       "\n",
       "   vegetacao_natural  nao_vegetacao_natural  hidrografia  \n",
       "0            11650.7                   89.4        435.9  \n",
       "1            11647.3                   89.4        435.9  \n",
       "2            11643.5                   89.4        435.9  \n",
       "3            11646.5                   89.4        435.9  \n",
       "4            11643.5                   89.4        435.9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazonas = pd.read_csv('amazonas_desmatamento.csv')\n",
    "df_amazonas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bioma\n",
       "Amazônia    1426\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_amazonas.groupby('municipio').size()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envunb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
